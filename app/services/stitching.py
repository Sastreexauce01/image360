"""
Service de stitching simplifi√© pour smartphone.
Fonctions essentielles : cr√©ation panorama + conversion √©quirectangulaire.
"""

import cv2
import numpy as np
from PIL import Image
from typing import List, Tuple
from fastapi import UploadFile
import tempfile
import os
import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor

from app.core.config import settings
from app.utils.file import FileManager

logger = logging.getLogger(__name__)

class StitchingService:
    """Service simplifi√© de stitching pour photos smartphone."""
    
    def __init__(self):
        self.file_manager = FileManager()
        self.executor = ThreadPoolExecutor(max_workers=1)
        logger.info("StitchingService simplifi√© initialis√©")
    
    async def create_360_panorama(
        self,
        images: List[UploadFile],
        quality: str = "medium",
        output_format: str = "jpg",
        resolution: str = "2K"
    ) -> Image.Image:
        """
        Cr√©e un panorama 360¬∞ √† partir d'images smartphone.
        
        Args:
            images: Liste des images upload√©es
            quality: Qualit√© ("low", "medium", "high")
            output_format: Format de sortie
            resolution: R√©solution finale
            
        Returns:
            Image panoramique PIL
        """
        temp_files = []
        
        try:
            logger.info(f"üöÄ D√©but traitement {len(images)} images smartphone")
            
            # 1. Sauvegarde des images
            temp_files = await self.file_manager.save_uploaded_files(images)
            
            # 2. Traitement synchrone avec timeout
            result = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    self.executor,
                    self._process_smartphone_images,
                    temp_files,
                    quality,
                    resolution
                ),
                timeout=300.0  # 5 minutes max
            )
            
            logger.info("‚úÖ Traitement termin√© avec succ√®s")
            return result
            
        except asyncio.TimeoutError:
            logger.error("‚ùå Timeout: traitement trop long")
            raise Exception("Le traitement a pris trop de temps")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur: {e}")
            raise Exception(f"Erreur lors de la g√©n√©ration: {str(e)}")
            
        finally:
            # Nettoyage
            await self.file_manager.cleanup_files(temp_files)
    
    def _process_smartphone_images(
        self,
        image_paths: List[str],
        quality: str,
        resolution: str
    ) -> Image.Image:
        """Traitement principal des images smartphone."""
        
        try:
            # 1. Chargement des images
            logger.info("üì∑ Chargement des images...")
            cv_images = self._load_smartphone_images(image_paths, quality)
            
            if len(cv_images) < 2:
                raise Exception("Impossible de charger au moins 2 images valides")
            
            # 2. Cr√©ation du panorama
            logger.info("üîÑ Cr√©ation du panorama...")
            panorama = self._create_panorama(cv_images)
            
            # 3. Conversion √©quirectangulaire
            logger.info("üåê Conversion √©quirectangulaire...")
            equirectangular = self._convert_to_equirectangular(panorama, resolution)
            
            # 4. Conversion en PIL
            rgb_image = cv2.cvtColor(equirectangular, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_image)
            
            logger.info(f"‚úÖ Panorama cr√©√©: {pil_image.size}")
            return pil_image
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement: {e}")
            raise Exception(f"√âchec du traitement: {str(e)}")
    
    def _load_smartphone_images(self, image_paths: List[str], quality: str) -> List[np.ndarray]:
        """Charge les images avec optimisation smartphone."""
        
        # Tailles selon qualit√©
        max_sizes = {
            "low": 600,
            "medium": 800, 
            "high": 1200
        }
        max_size = max_sizes.get(quality, 800)
        
        cv_images = []
        
        for i, path in enumerate(image_paths):
            try:
                # Chargement simple
                img = cv2.imread(path)
                if img is None:
                    logger.warning(f"‚ö†Ô∏è Image {i+1} non charg√©e")
                    continue
                
                h, w = img.shape[:2]
                logger.info(f"üì∑ Image {i+1}: {w}x{h}")
                
                # Validation taille minimum
                if min(h, w) < 300:
                    logger.warning(f"‚ö†Ô∏è Image {i+1} trop petite")
                    continue
                
                # Redimensionnement si n√©cessaire
                if max(h, w) > max_size:
                    scale = max_size / max(h, w)
                    new_w = int(w * scale)
                    new_h = int(h * scale)
                    
                    img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
                    logger.info(f"üìè Image {i+1} redimensionn√©e: {new_w}x{new_h}")
                
                # Am√©lioration simple du contraste
                img = self._enhance_image(img)
                
                cv_images.append(img)
                logger.info(f"‚úÖ Image {i+1} ajout√©e")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur image {i+1}: {e}")
                continue
        
        logger.info(f"üì∑ {len(cv_images)} images charg√©es")
        return cv_images
    
    def _enhance_image(self, img: np.ndarray) -> np.ndarray:
        """Am√©lioration simple d'image pour smartphone."""
        try:
            # Am√©lioration l√©g√®re du contraste
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE l√©ger
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            enhanced = cv2.merge([l, a, b])
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            
            return enhanced
            
        except Exception:
            return img  # Retourne l'original si erreur
    
    def _create_panorama(self, cv_images: List[np.ndarray]) -> np.ndarray:
        """
        FONCTION ESSENTIELLE: Cr√©ation du panorama smartphone.
        Utilise plusieurs strat√©gies pour maximiser les chances de succ√®s.
        """
        logger.info(f"üîÑ Stitching de {len(cv_images)} images...")
        
        # Strat√©gie 1: Mode SCANS (meilleur pour photos non-organis√©es)
        try:
            logger.info("üîÑ Tentative mode SCANS...")
            stitcher = cv2.Stitcher.create(cv2.Stitcher_SCANS)
            stitcher.setPanoConfidenceThresh(0.1)  # Tr√®s permissif
            
            status, panorama = stitcher.stitch(cv_images)
            
            if status == cv2.Stitcher_OK and panorama is not None and panorama.size > 0:
                logger.info("‚úÖ Stitching SCANS r√©ussi!")
                return panorama
            else:
                logger.warning(f"‚ö†Ô∏è Mode SCANS √©chou√©: {status}")
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur mode SCANS: {e}")
        
        # Strat√©gie 2: Mode PANORAMA permissif
        try:
            logger.info("üîÑ Tentative mode PANORAMA...")
            stitcher = cv2.Stitcher.create(cv2.Stitcher_PANORAMA)
            stitcher.setPanoConfidenceThresh(0.1)
            
            status, panorama = stitcher.stitch(cv_images)
            
            if status == cv2.Stitcher_OK and panorama is not None and panorama.size > 0:
                logger.info("‚úÖ Stitching PANORAMA r√©ussi!")
                return panorama
            else:
                logger.warning(f"‚ö†Ô∏è Mode PANORAMA √©chou√©: {status}")
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur mode PANORAMA: {e}")
        
        # Strat√©gie 3: Images encore plus petites
        if len(cv_images) > 2:
            try:
                logger.info("üîÑ Tentative avec images tr√®s r√©duites...")
                small_images = []
                for img in cv_images:
                    h, w = img.shape[:2]
                    small_img = cv2.resize(img, (w//2, h//2), interpolation=cv2.INTER_AREA)
                    small_images.append(small_img)
                
                stitcher = cv2.Stitcher.create(cv2.Stitcher_SCANS)
                stitcher.setPanoConfidenceThresh(0.05)  # Extr√™mement permissif
                
                status, panorama = stitcher.stitch(small_images)
                
                if status == cv2.Stitcher_OK and panorama is not None and panorama.size > 0:
                    logger.info("‚úÖ Stitching images r√©duites r√©ussi!")
                    return panorama
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur images r√©duites: {e}")
        
        # Strat√©gie 4: Fallback - prendre seulement les 2 premi√®res images
        if len(cv_images) >= 2:
            try:
                logger.info("üîÑ Fallback: stitching des 2 premi√®res images...")
                stitcher = cv2.Stitcher.create(cv2.Stitcher_SCANS)
                stitcher.setPanoConfidenceThresh(0.05)
                
                status, panorama = stitcher.stitch(cv_images[:2])
                
                if status == cv2.Stitcher_OK and panorama is not None and panorama.size > 0:
                    logger.info("‚úÖ Stitching 2 images r√©ussi!")
                    return panorama
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur fallback: {e}")
        
        # √âchec total
        raise Exception(
            "Impossible de cr√©er un panorama. "
            "Assurez-vous que vos images ont des zones de recouvrement visibles."
        )
    
    def _convert_to_equirectangular(self, panorama: np.ndarray, resolution: str) -> np.ndarray:
        """
        FONCTION ESSENTIELLE: Conversion en format √©quirectangulaire 360¬∞.
        Cr√©e le format standard pour la visualisation 360¬∞.
        """
        logger.info("üåê Conversion √©quirectangulaire...")
        
        try:
            h, w = panorama.shape[:2]
            logger.info(f"üìê Panorama original: {w}x{h}")
            
            # D√©finition des r√©solutions finales
            target_widths = {
                "2K": 2048,
                "4K": 4096,
                "8K": 8192
            }
            
            target_width = target_widths.get(resolution, 2048)
            target_height = target_width // 2  # Ratio 2:1 pour √©quirectangulaire
            
            logger.info(f"üéØ Cible √©quirectangulaire: {target_width}x{target_height}")
            
            # Redimensionnement vers le format √©quirectangulaire
            equirectangular = cv2.resize(
                panorama,
                (target_width, target_height),
                interpolation=cv2.INTER_LANCZOS4
            )
            
            # Am√©lioration finale
            equirectangular = self._final_enhancement(equirectangular)
            
            logger.info(f"‚úÖ √âquirectangulaire cr√©√©: {target_width}x{target_height}")
            return equirectangular
            
        except Exception as e:
            logger.error(f"‚ùå Erreur conversion √©quirectangulaire: {e}")
            # Fallback: redimensionnement simple
            target_width = 2048
            target_height = 1024
            return cv2.resize(panorama, (target_width, target_height))
    
    def _final_enhancement(self, img: np.ndarray) -> np.ndarray:
        """Am√©lioration finale de l'image √©quirectangulaire."""
        try:
            # R√©duction l√©g√®re du bruit
            enhanced = cv2.bilateralFilter(img, 5, 50, 50)
            
            # Correction gamma subtile
            gamma = 1.05
            inv_gamma = 1.0 / gamma
            table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            enhanced = cv2.LUT(enhanced, table)
            
            return enhanced
            
        except Exception:
            return img